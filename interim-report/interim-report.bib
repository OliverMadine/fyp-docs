@misc{curve,
  title = {Curve Finance's \$62M exploit exposes larger issues for DeFi ecosystem},
  author = {Jacquelyn Melinek},
  url = {https://techcrunch.com/2023/08/01/curve-finances-62m-exploit-exposes-larger-issues-for-defi-ecosystem/},
  day = {1},
  year = {2023},
  month = {aug},
  urldate = {2024.01.20},
}

@article{staged-selective,
  author = {Willis, Jamie and Wu, Nicolas and Pickering, Matthew},
  title = {Staged selective parser combinators},
  year = {2020},
  issue_date = {August 2020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {4},
  number = {ICFP},
  url = {https://doi.org/10.1145/3409002},
  doi = {10.1145/3409002},
  abstract = {Parser combinators are a middle ground between the fine control of hand-rolled parsers and the high-level almost grammar-like appearance of parsers created via parser generators. They also promote a cleaner, compositional design for parsers. Historically, however, they cannot match the performance of their counterparts.  This paper describes how to compile parser combinators into parsers of hand-written quality. This is done by leveraging the static information present in the grammar by representing it as a tree. However, in order to exploit this information, it will be necessary to drop support for monadic computation since this generates dynamic structure. Selective functors can help recover lost functionality in the absence of monads, and the parser tree can be partially evaluated with staging. This is implemented in a library called Parsley.},
  journal = {Proc. ACM Program. Lang.},
  month = {aug},
  articleno = {120},
  numpages = {30},
  keywords = {combinators, meta-programming, parsers},
}

@article{fuzzing-importance,
  author = {Marcozzi, Micha\"{e}l and Tang, Qiyi and Donaldson, Alastair F. and Cadar, Cristian},
  title = {Compiler fuzzing: how much does it matter?},
  year = {2019},
  issue_date = {October 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {3},
  number = {OOPSLA},
  url = {https://doi.org/10.1145/3360581},
  doi = {10.1145/3360581},
  abstract = {Despite much recent interest in randomised testing (fuzzing) of compilers, the practical impact of fuzzer-found compiler bugs on real-world applications has barely been assessed. We present the first quantitative and qualitative study of the tangible impact of miscompilation bugs in a mature compiler. We follow a rigorous methodology where the bug impact over the compiled application is evaluated based on (1) whether the bug appears to trigger during compilation; (2) the extent to which generated assembly code changes syntactically due to triggering of the bug; and (3) whether such changes cause regression test suite failures, or whether we can manually find application inputs that trigger execution divergence due to such changes. The study is conducted with respect to the compilation of more than 10 million lines of C/C++ code from 309 Debian packages, using 12\% of the historical and now fixed miscompilation bugs found by four state-of-the-art fuzzers in the Clang/LLVM compiler, as well as 18 bugs found by human users compiling real code or as a by-product of formal verification efforts. The results show that almost half of the fuzzer-found bugs propagate to the generated binaries for at least one package, in which case only a very small part of the binary is typically affected, yet causing two failures when running the test suites of all the impacted packages. User-reported and formal verification bugs do not exhibit a higher impact, with a lower rate of triggered bugs and one test failure. The manual analysis of a selection of the syntactic changes caused by some of our bugs (fuzzer-found and non fuzzer-found) in package assembly code, shows that either these changes have no semantic impact or that they would require very specific runtime circumstances to trigger execution divergence.},
  journal = {Proc. ACM Program. Lang.},
  month = {oct},
  articleno = {155},
  numpages = {29},
  keywords = {Clang, LLVM, bug impact, compilers, fuzzing, software testing},
}

@inproceedings{10.1145/351240.351266,
author = {Claessen, Koen and Hughes, John},
title = {QuickCheck: a lightweight tool for random testing of Haskell programs},
year = {2000},
isbn = {1581132026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/351240.351266},
doi = {10.1145/351240.351266},
abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
booktitle = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
pages = {268–279},
numpages = {12},
series = {ICFP '00},
}

@article{quickcheck,
  author = {Claessen, Koen and Hughes, John},
  title = {QuickCheck: a lightweight tool for random testing of Haskell programs},
  year = {2000},
  issue_date = {Sept. 2000},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {35},
  number = {9},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/357766.351266},
  doi = {10.1145/357766.351266},
  abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
  journal = {SIGPLAN Not.},
  month = {sep},
  pages = {268–279},
  numpages = {12},
}

